{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=open('names.txt','r').read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u', 'w', 'r', 'e', 't', 'h', 'd', 'f', 'n', 'o', 'i', 'k', 'm', 'j', 'x', 'l', 'b', 's', 'c', 'p', 'g', 'q', 'z', 'y', 'v', 'a'}\n",
      "['u', 'w', 'r', 'e', 't', 'h', 'd', 'f', 'n', 'o', 'i', 'k', 'm', 'j', 'x', 'l', 'b', 's', 'c', 'p', 'g', 'q', 'z', 'y', 'v', 'a']\n",
      "{'u': 1, 'w': 2, 'r': 3, 'e': 4, 't': 5, 'h': 6, 'd': 7, 'f': 8, 'n': 9, 'o': 10, 'i': 11, 'k': 12, 'm': 13, 'j': 14, 'x': 15, 'l': 16, 'b': 17, 's': 18, 'c': 19, 'p': 20, 'g': 21, 'q': 22, 'z': 23, 'y': 24, 'v': 25, 'a': 26, '.': 0}\n",
      "{1: 'u', 2: 'w', 3: 'r', 4: 'e', 5: 't', 6: 'h', 7: 'd', 8: 'f', 9: 'n', 10: 'o', 11: 'i', 12: 'k', 13: 'm', 14: 'j', 15: 'x', 16: 'l', 17: 'b', 18: 's', 19: 'c', 20: 'p', 21: 'g', 22: 'q', 23: 'z', 24: 'y', 25: 'v', 26: 'a', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars=(list(set(''.join(words))))\n",
    "print(chars)\n",
    "stoi={s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "print(stoi)\n",
    "\n",
    "\n",
    "itos={i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train set all bigrams (x,y)\n",
    "\n",
    "xs,ys=[],[]\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs=['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1=stoi[ch1]\n",
    "        ix2=stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs=torch.tensor(xs)\n",
    "ys=torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  6, 19, 19,  2]), tensor([ 6, 19, 19,  2,  0]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 27])\n",
      "torch.Size([5, 27])\n",
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x117df9b80>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xenc=F.one_hot(xs,num_classes=27).float()\n",
    "yenc=F.one_hot(ys,num_classes=27)\n",
    "\n",
    "print(Xenc.shape)\n",
    "print(yenc.shape)\n",
    "print(Xenc.dtype)\n",
    "plt.imshow(Xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8326,  0.3096, -1.1333, -2.6611,  0.4248,  0.1295,  0.6513,  0.2090,\n",
       "         -0.3359,  0.8825,  0.4246, -0.3021,  0.9402,  1.9511, -1.1221, -0.1889,\n",
       "          0.4093,  0.5503,  1.0858,  2.2083, -0.6417,  0.5071,  0.2465,  1.6482,\n",
       "          0.6120,  2.2739,  0.0708],\n",
       "        [ 0.6144, -0.4925, -0.6751, -0.6284, -1.7264, -0.8004, -1.3254,  0.2146,\n",
       "         -0.6013, -0.0709,  1.0101, -1.3193,  0.4369,  0.5600, -0.2217,  1.4075,\n",
       "         -0.3330, -0.7979,  1.9307, -0.1861,  0.4330,  0.8769, -0.5894,  2.2420,\n",
       "          2.6153,  0.6719, -0.3038],\n",
       "        [ 1.2965,  2.0130,  0.3627, -0.0713,  0.2677,  0.9051, -1.7248, -1.8615,\n",
       "          1.8012, -0.4092,  0.5193,  0.4123,  1.1448,  0.3674, -0.4539,  0.9960,\n",
       "         -0.5514, -1.3231,  0.7652,  1.2804, -0.6412, -1.2192,  0.6931, -2.2012,\n",
       "          1.1742,  0.4635,  0.3279],\n",
       "        [ 1.2965,  2.0130,  0.3627, -0.0713,  0.2677,  0.9051, -1.7248, -1.8615,\n",
       "          1.8012, -0.4092,  0.5193,  0.4123,  1.1448,  0.3674, -0.4539,  0.9960,\n",
       "         -0.5514, -1.3231,  0.7652,  1.2804, -0.6412, -1.2192,  0.6931, -2.2012,\n",
       "          1.1742,  0.4635,  0.3279],\n",
       "        [-0.4222,  1.2937,  0.4704,  0.5512, -0.0648, -0.9678,  0.4362,  0.5107,\n",
       "         -0.1547,  0.3793, -0.7484,  0.1875, -0.5992, -0.0933, -1.5273,  0.1564,\n",
       "          0.2498, -1.6825,  1.2606,  0.6325,  0.5815, -0.1300,  1.5089, -2.1127,\n",
       "          1.8198,  0.0160,  0.9354]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Matrix Multiplication\n",
    "W=torch.randn((27,27))\n",
    "\n",
    "(Xenc @ W)\n",
    "# (5,27) * (27,1) = (5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Xenc[3] @ W[:,13]).sum() ==(Xenc @ W)[3,13] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=(Xenc @ W)\n",
    "counts=logits.exp()\n",
    "probs=counts/counts.sum(1,keepdims=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n",
      "torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "print(probs[0].sum())\n",
    "print(probs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  6, 19, 19,  2])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 19, 19,  2,  0])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly initialize 27 neurons and each neuron receives 27 inputs\n",
    "g=torch.Generator().manual_seed(2147483647)\n",
    "W=torch.randn((27,27),generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward pass\n",
    "xenc=F.one_hot(xs,num_classes=27).float() # input the network:one hot encoding\n",
    "logits=(xenc @ W) # predict log counts\n",
    "counts=logits.exp() # counts, equivelant to N\n",
    "\n",
    "probs=counts / counts.sum(1,keepdim=True) # probabilities for next character\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Bigram example 1:.e (indexes 0,6)\n",
      "input to the neural net: 0\n",
      "label (actual next character) 6\n",
      "probability assigned by the net to the correct character: 0.0026941029354929924\n",
      "log likelihood -5.916689872741699\n",
      "negative log likelihood 5.916689872741699\n",
      "==========\n",
      "average negative log likelihood i.e:loss= 5.916689872741699\n"
     ]
    }
   ],
   "source": [
    "nlls=torch.zeros(1)\n",
    "\n",
    "for i in range(1):\n",
    "    x=xs[i].item()\n",
    "    y=ys[i].item()\n",
    "    \n",
    "    print('--------')\n",
    "    print(f'Bigram example {i+1}:{itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "    print('input to the neural net:',x)\n",
    "    print('label (actual next character)',y)\n",
    "    p=probs[i,y]\n",
    "    print('probability assigned by the net to the correct character:',p.item())\n",
    "    logp=torch.log(p)\n",
    "    print('log likelihood',logp.item())\n",
    "    nll=-logp\n",
    "    print('negative log likelihood',nll.item())\n",
    "    nlls[i]=nll\n",
    "    \n",
    "print('==========')\n",
    "print('average negative log likelihood i.e:loss=',nlls.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0123, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0115, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0287, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0121, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0249, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss fonksiyonu hesabı için olasıkları istiyoruz ama alttaki gibi zor yoldan değil\n",
    "\n",
    "probs[0,5],probs[1,13],probs[2,13],probs[3,1],probs[4,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  6, 19, 19,  2])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 19, 19,  2,  0])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly initialize 27 neurons and each neuron receives 27 inputs\n",
    "\n",
    "g=torch.Generator().manual_seed(2147483647)\n",
    "W=torch.randn(27,27,generator=g,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward pass\n",
    "xenc=F.one_hot(xs,num_classes=27).float() # input the network:one hot encoding\n",
    "logits=(xenc @ W) # predict log counts\n",
    "counts=logits.exp() # counts, equivelant to N\n",
    "\n",
    "probs=counts / counts.sum(1,keepdim=True) # probabilities for next character\n",
    "\n",
    "loss=-probs[torch.arange(5),ys].log().mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.634944915771484\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Pass\n",
    "W.grad=None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Weights\n",
    "W.data+=-0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6807148456573486\n",
      "2.6636157035827637\n",
      "2.648829221725464\n",
      "2.63590145111084\n",
      "2.6245028972625732\n",
      "2.614387035369873\n",
      "2.6053595542907715\n",
      "2.5972673892974854\n",
      "2.589984655380249\n",
      "2.583407163619995\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(10):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jana.\n",
      "kahtuscenadbin.\n",
      "gh.\n",
      "adoifma.\n",
      "jlelyuteri.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
